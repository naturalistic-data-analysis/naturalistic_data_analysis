---
interact_link: content/features/notebooks/hypertools.ipynb
kernel_name: python3
kernel_path: content/features/notebooks
has_widgets: false
title: |-
  Visualizing High Dimensional Data
pagenum: 14
prev_page:
  url: /features/notebooks/Pliers_Tutorial.html
next_page:
  url: /features/notebooks/1_Introduction_to_Programming.html
suffix: .ipynb
search: hypertools data org sherlock into dataset d using also well model paper space dimensional visualization pipeline here notebooks participants embedding responses cortex different high visual patterns html text across readthedocs io en latest toolbox www pdf github com set used matrices topic shape visualize neural additional contextlab example generate following columns features dimension lets g examine auditory motor brain movie shared episode content window tools subject idea properties useful gain tutorial jmlr papers single rows timepoints feature note same reduce plot command download naturalistic next e roi primary regions show agreement v sense response annotations sliding code provides insights multi

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Visualizing High Dimensional Data</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Overview">Overview<a class="anchor-link" href="#Overview"> </a></h1><p><em>Written by Jeremy Manning</em></p>
<p>The <a href="https://hypertools.readthedocs.io/en/latest/">HyperTools</a> Python toolbox provides tools for gaining "geometric insights" into high-dimensional multi-subject datasets.  The overarching idea of the toolbox is to use a series of data processing and visualization approaches to turn a dataset into a 2D or 3D shape or animation that reflects key properties of the original dataset.  This can be a useful way to gain intuitions about a dataset, since our visual systems are adept at identifying complex patterns in visual data.  In this tutorial we will use HyperTools to visualize some neural and behavioral data.</p>
<h2 id="The-HyperTools-data-visualization-pipeline">The HyperTools data visualization pipeline<a class="anchor-link" href="#The-HyperTools-data-visualization-pipeline"> </a></h2><p>At its core, the HyperTools toolbox provides a suite of wrappers for myriad functions in the <a href="https://scikit-learn.org/stable/">scikit-learn</a>, <a href="http://www.pymvpa.org/">pymvpa</a>, <a href="https://brainiak.org/">braniak</a>, and <a href="https://seaborn.pydata.org/">seaborn</a> toolboxes, among others.  A short JMLR paper describing the HyperTools analysis pipeline may be found <a href="http://www.jmlr.org/papers/volume18/17-434/17-434.pdf">here</a>, and a long-form preprint with additional details may be found <a href="https://arxiv.org/pdf/1701.08290.pdf">here</a>.  <a href="https://github.com/ContextLab/hypertools-paper-notebooks">This repository</a> also contains additional example notebooks.  If you are looking for an alternative introduction to the toolbox with some additional demos, you may be interested in this video:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;hb_ER9RGtOM&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/hb_ER9RGtOM"
    frameborder="0"
    allowfullscreen
></iframe>

</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <strong>HyperTools data visualization pipeline</strong> defines a set of heuristics for preprocessing a high-dimensional multi-subject dataset and generating a visualization that may be used to gain useful insights into the data.  The idea is to generate visualizable 2D and 3D shapes and animations that reflect key properties of the data.  For example, this visualization displays several participants' unfolding neural patterns as they listen to a 10-minute story (here each line represents the neural activity patterns of a single person):
<img src="https://hypertools.readthedocs.io/en/latest/_images/hypertools.gif" alt="250px"></p>
<p>The pipeline comprises the following steps:</p>
<ol>
<li>Wrangle the dataset into a list of numerical matrices (<em>one matrix per subject</em>).  The matrices' <em>rows denote timepoints</em> and their <em>columns denote features</em> (a feature may be a voxel, electrode, a word embedding dimension, a label or category, or some other set of observable or quantifiable values).  Note that, for some data types, this wrangling process is non-trivial.  HyperTools incorporates useful functions for <a href="https://hypertools.readthedocs.io/en/latest/hypertools.tools.format_data.html#hypertools.tools.format_data">parsing</a> a variety of datatypes, including text data.  The <a href="https://github.com/tyarkoni/pliers">pliers</a> toolbox may also be used to generate HyperTools-compatable feature vectors for a wider range of datatypes.</li>
<li>Normalize (<em>z</em>-score) within each matrix column to ensure that all dimensions have equal representation in the final visualization.  (This step is optional.)  Pad matrices with columns of zeros as needed, to ensure they all have the same number of columns ($k$).  Note that all matrices must have the same number of rows (number of rows/timepoints: $t$).</li>
<li><a href="http://haxbylab.dartmouth.edu/publications/HGC+11.pdf">Hyperalign</a> the matrices into a common space.</li>
<li><a href="https://hypertools.readthedocs.io/en/latest/hypertools.reduce.html#hypertools.reduce">Embed</a> the hyperaligned data into a low-dimensional space (typically this space will be either 2D or 3D).</li>
<li>Generate a plot or animation of the reduced data.</li>
</ol>
<p>If a dataset is stored in the list <code>data</code>, the HyperTools pipeline may be used to generate a visualization using a single command:</p>

<pre><code>import hypertools as hyp
hyp.plot(data)</code></pre>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Download-Sherlock-dataset">Download Sherlock dataset<a class="anchor-link" href="#Download-Sherlock-dataset"> </a></h2><p>Follow the instructions <a href="http://naturalistic-data.org/features/notebooks/Download_Data.html">here</a> to download the Sherlock dataset using DataLad.  In brief, navigate to a directory where you want to save the datasets (let's refer to it as <code>datadir</code>) and run the following command in Terminal:</p>

<pre><code>datalad install -g https://gin.g-node.org/ljchang/Sherlock</code></pre>
<p>In the next cell, set the variable <code>datadir</code> to the actual path you chose (e.g. <code>~/data</code>)</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">datadir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;HOME&#39;</span><span class="p">),</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Import-libraries">Import libraries<a class="anchor-link" href="#Import-libraries"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span> <span class="k">as</span> <span class="n">lsdir</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">scipy.interpolate</span> <span class="kn">import</span> <span class="n">pchip</span>
<span class="kn">from</span> <span class="nn">nltools.mask</span> <span class="kn">import</span> <span class="n">create_sphere</span><span class="p">,</span> <span class="n">expand_mask</span>
<span class="kn">from</span> <span class="nn">nltools.data</span> <span class="kn">import</span> <span class="n">Brain_Data</span><span class="p">,</span> <span class="n">Adjacency</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_stat_map</span>

<span class="kn">import</span> <span class="nn">hypertools</span> <span class="k">as</span> <span class="nn">hyp</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">timecorr</span> <span class="k">as</span> <span class="nn">tc</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="ROI-responses-while-viewing-Sherlock">ROI responses while viewing Sherlock<a class="anchor-link" href="#ROI-responses-while-viewing-Sherlock"> </a></h1><p>Following the <a href="http://naturalistic-data.org/features/notebooks/Functional_Alignment.html">functional alignment tutorial</a>, we'll select out voxels in early visual cortex from the <em>Sherlock</em> dataset.  We'll also examine primary auditory cortex and motor cortex responses.  Then we'll apply the HyperTools pipeline to the dataset and visualize the responses within each ROI as a 3D image.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="s1">&#39;http://neurovault.org/media/images/2099/Neurosynth%20Parcellation_0.nii.gz&#39;</span><span class="p">)</span>
<span class="n">vectorized_mask</span> <span class="o">=</span> <span class="n">expand_mask</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
<span class="n">mask</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_8_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rois</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/naturalistic-data-analysis/tutorial_development/master/hypertools/rois.csv&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ID&#39;</span><span class="p">,</span> <span class="s1">&#39;Region&#39;</span><span class="p">])</span>
<span class="n">rois</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Region</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>Anterior MPFC</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>Fusiform/parahippocampus</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2</td>
      <td>DMPFC</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3</td>
      <td>Sensorimotor/postcentral gyrus</td>
    </tr>
    <tr>
      <td>4</td>
      <td>4</td>
      <td>V1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">roi_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;V1&#39;</span><span class="p">,</span> <span class="s1">&#39;A1&#39;</span><span class="p">,</span> <span class="s1">&#39;Precentral gyrus&#39;</span><span class="p">]</span>
<span class="n">roi_ids</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">rois</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Region == &quot;</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)[</span><span class="s1">&#39;ID&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">roi_names</span><span class="p">]</span>
<span class="n">my_rois</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">roi_names</span><span class="p">,</span> <span class="n">roi_ids</span><span class="p">)}</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">extract_roi_data</span><span class="p">(</span><span class="n">fname_template</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">roi_id</span><span class="p">):</span>
    <span class="n">fnames</span> <span class="o">=</span> <span class="n">lsdir</span><span class="p">(</span><span class="n">fname_template</span><span class="p">)</span>
    <span class="n">roi_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fnames</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;extracting data for ROI </span><span class="si">{</span><span class="n">roi_id</span><span class="si">}</span><span class="s1">: &#39;</span> <span class="o">+</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">sep</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">40</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span><span class="p">)</span>
        <span class="n">roi_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Brain_Data</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">apply_mask</span><span class="p">(</span><span class="n">mask</span><span class="p">[</span><span class="n">roi_id</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">roi_data</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define filename templates</span>
<span class="n">sherlock_part1</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">datadir</span><span class="p">,</span> <span class="s1">&#39;Sherlock&#39;</span><span class="p">,</span> <span class="s1">&#39;fmriprep&#39;</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;func&#39;</span><span class="p">,</span> <span class="s1">&#39;*crop*Part1*hdf5&#39;</span><span class="p">)</span>
<span class="n">sherlock_part2</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">datadir</span><span class="p">,</span> <span class="s1">&#39;Sherlock&#39;</span><span class="p">,</span> <span class="s1">&#39;fmriprep&#39;</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;func&#39;</span><span class="p">,</span> <span class="s1">&#39;*crop*Part2*hdf5&#39;</span><span class="p">)</span>
<span class="n">parts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;part 1&#39;</span><span class="p">:</span> <span class="n">sherlock_part1</span><span class="p">,</span> <span class="s1">&#39;part 2&#39;</span><span class="p">:</span> <span class="n">sherlock_part2</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parts</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">roi_data</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">my_rois</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">roi_data</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">extract_roi_data</span><span class="p">(</span><span class="n">parts</span><span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">vectorized_mask</span><span class="p">,</span> <span class="n">my_rois</span><span class="p">[</span><span class="n">r</span><span class="p">])</span>
    <span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">roi_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>extracting data for ROI 4: sub-13_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-14_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-15_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-12_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-08_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-01_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-06_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-07_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-09_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-10_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-11_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-16_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-05_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-02_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-03_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-04_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-13_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-14_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-15_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-12_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-08_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-01_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-06_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-07_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-09_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-10_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-11_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-16_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-05_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-02_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-03_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-04_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-13_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-14_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-15_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-12_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-08_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-01_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-06_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-07_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-09_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-10_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-11_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-16_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-05_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-02_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-03_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-04_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-13_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-14_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-15_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-12_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-08_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-01_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-06_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-07_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-09_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-10_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-11_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-16_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-05_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-02_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-03_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 4: sub-04_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-13_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-14_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-15_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-12_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-08_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-01_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-06_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-07_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-09_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-10_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-11_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-16_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-05_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-02_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-03_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 35: sub-04_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-13_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-14_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-15_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-12_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-08_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-01_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-06_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-07_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-09_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-10_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-11_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-16_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-05_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-02_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-03_denoise_crop_smooth6mm_task-sherl...
extracting data for ROI 9: sub-04_denoise_crop_smooth6mm_task-sherl...
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Getting-some-intuitions-for-the-Sherlock-data-using-HyperTools">Getting some intuitions for the Sherlock data using HyperTools<a class="anchor-link" href="#Getting-some-intuitions-for-the-Sherlock-data-using-HyperTools"> </a></h1><h2 id="Examining-brain-responses-in-visual,-auditory,-and-motor-cortex-during-movie-watching">Examining brain responses in visual, auditory, and motor cortex during movie watching<a class="anchor-link" href="#Examining-brain-responses-in-visual,-auditory,-and-motor-cortex-during-movie-watching"> </a></h2><p>Participants in the Sherlock experiment all watched the same audiovisual movie.  Therefore, to the extent that participants' brain responses were driven by the movie, we might expect that their brain responses in primary auditory and visual cortex should follow similar or related patterns.  In contrast, non-sensory regions like primary motor cortex should not show this sort of agreement.</p>
<p>We can test this intuition qualitatively by projecting the ROI data from visual, auditory, and motor cortex into a shared low-dimensional space.  Each participant's trajectory will be plotted in a different color.  Regions that show greater agreement across participants will have more similarly shaped (overlapping) trajectories when plotted using the HyperTools pipeline.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plot_aligned_ROI_trajectories</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s1">&#39;UMAP&#39;</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;hyper&#39;</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ndims</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">internal_reduce</span><span class="o">=</span><span class="s1">&#39;IncrementalPCA&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span> <span class="c1">#roi</span>
            <span class="n">plot_aligned_ROI_trajectories</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">r</span><span class="p">],</span> <span class="n">reduce</span><span class="o">=</span><span class="n">reduce</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">,</span> <span class="n">ndims</span><span class="o">=</span><span class="n">ndims</span><span class="p">,</span> <span class="n">internal_reduce</span><span class="o">=</span><span class="n">internal_reduce</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1">#step 1: reduce dataset before aligning (runs much faster)</span>
        <span class="n">reduced_data</span> <span class="o">=</span> <span class="n">hyp</span><span class="o">.</span><span class="n">reduce</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">],</span> <span class="n">reduce</span><span class="o">=</span><span class="n">internal_reduce</span><span class="p">,</span> <span class="n">ndims</span><span class="o">=</span><span class="n">ndims</span><span class="p">)</span>

        <span class="c1">#step 2: smooth trajectories so they look prettier</span>
        <span class="n">smoothed_data</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">smooth</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">,</span> <span class="n">kernel_fun</span><span class="o">=</span><span class="n">tc</span><span class="o">.</span><span class="n">helpers</span><span class="o">.</span><span class="n">gaussian_weights</span><span class="p">,</span> <span class="n">kernel_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;var&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">})</span>
        
        <span class="c1">#step 3: align trajectories</span>
        <span class="n">aligned_data</span> <span class="o">=</span> <span class="n">smoothed_data</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
            <span class="n">aligned_data</span> <span class="o">=</span> <span class="n">hyp</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">aligned_data</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">)</span>

        <span class="c1">#now generate a plot</span>
        <span class="n">hyp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">aligned_data</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="n">reduce</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_aligned_ROI_trajectories</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;part 1&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_16_0.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_16_1.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_16_2.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see strong agreement across people in V1 and A1, whereas precentral gyrus responses are much more variable.  Now let's see if these patterns also hold for the second half of the dataset:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_aligned_ROI_trajectories</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;part 2&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_18_0.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_18_1.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_18_2.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It looks like this pattern holds!  To test this idea formally, we could develop a measure of trajectory consistency across people (e.g. mean squared error between the corresponding timepoints, across all pairs of participants' trajectories).  We could also explore the extent to which different brain regions exhibit consistent patterns across people.</p>
<h3 id="Using-different-embedding-spaces-to-obtain-a-more-complete-sense-of-high-dimensional-space">Using different embedding spaces to obtain a more complete sense of high-dimensional space<a class="anchor-link" href="#Using-different-embedding-spaces-to-obtain-a-more-complete-sense-of-high-dimensional-space"> </a></h3><p>When we visualize high-dimensional data as 3D shapes, we necessarily lose information.  One strategy for getting a better sense of the "true shape" of the data is to use different projection algorithms for embedding the data into the 3D space (this may be done using the <code>reduce</code> keyword).</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">first_roi</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;part 1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plot_aligned_ROI_trajectories</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;part 1&#39;</span><span class="p">][</span><span class="n">first_roi</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;hyper&#39;</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s1">&#39;IncrementalPCA&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">first_roi</span><span class="si">}</span><span class="s1">: Incremental PCA&#39;</span><span class="p">)</span>
<span class="n">plot_aligned_ROI_trajectories</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;part 1&#39;</span><span class="p">][</span><span class="n">first_roi</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;hyper&#39;</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s1">&#39;MiniBatchDictionaryLearning&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">first_roi</span><span class="si">}</span><span class="s1">: Mini batch dictionary learning&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_20_0.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_20_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In both of these examples we can still see the high degree of consistency across people.  Each embedding approach amplifies preserves or emphasizes a different set of properties from the original high-dimensional feature space.</p>
<h3 id="Aligning-using-the-shared-response-model">Aligning using the shared response model<a class="anchor-link" href="#Aligning-using-the-shared-response-model"> </a></h3><p>The above examples use hyperalignment to map different participants' data into a common space.  HyperTools also supports alignment using the <a href="https://papers.nips.cc/paper/5855-a-reduced-dimension-fmri-shared-response-model">Shared Response Model (SRM)</a>:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_aligned_ROI_trajectories</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;part 1&#39;</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;SRM&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_22_0.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_22_1.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_22_2.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-is-the-&quot;shape&quot;-of-the-Sherlock-episode?">What is the "shape" of the Sherlock episode?<a class="anchor-link" href="#What-is-the-&quot;shape&quot;-of-the-Sherlock-episode?"> </a></h2><p>Following an approach similar to the one used in <a href="https://www.biorxiv.org/content/10.1101/409987v1">this paper</a>, we can use also HyperTools to examine how the content of the Sherlock episode unfolds.  Whereas the analyses above show how HyperTools may be used to gain insight into dynamics in neural data, we can also use HyperTools to examine how the semantic content of the episode changes over time.  We'll fit a word embedding model to a set of detailed annotations of each scene in the episode.</p>
<p>First, let's download the annotations to get a sense of what they're like.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">dest</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dest</span><span class="p">):</span>
        <span class="n">stream</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
            <span class="n">fd</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># raw annotations</span>
<span class="n">annotations_source</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/ContextLab/sherlock-topic-model-paper/raw/revision-1/data/raw/Sherlock_Segments_1000_NN_2017.xlsx&#39;</span>
<span class="n">annotations_dest</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">datadir</span><span class="p">,</span> <span class="s1">&#39;Sherlock&#39;</span><span class="p">,</span> <span class="s1">&#39;stimuli&#39;</span><span class="p">,</span> <span class="s1">&#39;annotations.xlsx&#39;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="n">annotations_source</span><span class="p">,</span> <span class="n">annotations_dest</span><span class="p">)</span>
<span class="n">annotations</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">annotations_dest</span><span class="p">)</span>
<span class="n">annotations</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Segment Number</th>
      <th>Start Time (s)</th>
      <th>End Time (s)</th>
      <th>Start Time (TRs, 1.5s)</th>
      <th>End Time (TRs, 1.5s)</th>
      <th>Scene Segments</th>
      <th>Scene Details - A Level</th>
      <th>Space-In/Outdoor</th>
      <th>Name - All</th>
      <th>Name - Focus</th>
      <th>...</th>
      <th>Music Presence</th>
      <th>Words on Screen</th>
      <th>Arousal - Rater 1</th>
      <th>Valence - Rater 1</th>
      <th>Arousal - Rater 2</th>
      <th>Valence - Rater 2</th>
      <th>Arousal - Rater 3</th>
      <th>Valence - Rater 3</th>
      <th>Arousal - Rater 4</th>
      <th>Valence - Rater 4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>12</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>1. Cartoon</td>
      <td>People in popcorn, candy, and soft drink costu...</td>
      <td>Indoor</td>
      <td>Cartoon People in Costumes</td>
      <td>Cartoon People in Costumes</td>
      <td>...</td>
      <td>Yes</td>
      <td>NaN</td>
      <td>3</td>
      <td>+</td>
      <td>1</td>
      <td>+</td>
      <td>2</td>
      <td>+</td>
      <td>3</td>
      <td>+</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2</td>
      <td>12</td>
      <td>15</td>
      <td>9.0</td>
      <td>10.0</td>
      <td>NaN</td>
      <td>Popcorn is being popped in a large popcorn mac...</td>
      <td>Indoor</td>
      <td>Female Singer</td>
      <td>NaN</td>
      <td>...</td>
      <td>Yes</td>
      <td>NaN</td>
      <td>3</td>
      <td>+</td>
      <td>1</td>
      <td>+</td>
      <td>2</td>
      <td>+</td>
      <td>2</td>
      <td>+</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3</td>
      <td>15</td>
      <td>17</td>
      <td>11.0</td>
      <td>11.0</td>
      <td>NaN</td>
      <td>Men sing in reply: "the popcorn can't be beat!"</td>
      <td>Indoor</td>
      <td>Male Singers</td>
      <td>NaN</td>
      <td>...</td>
      <td>Yes</td>
      <td>NaN</td>
      <td>3</td>
      <td>+</td>
      <td>1</td>
      <td>+</td>
      <td>2</td>
      <td>+</td>
      <td>2</td>
      <td>+</td>
    </tr>
  </tbody>
</table>
<p>3 rows  23 columns</p>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we'll preprocess the anotations in sliding windows of (up to) 50 segments.  In each sliding window, we'll concatenate all of the text into a single "blob" that merges all of the columns of the annotation spreadsheet, from all of the segments in that window.  Note that the preprocessing was carried out using the code in <a href="https://github.com/ContextLab/sherlock-topic-model-paper/blob/revision-1/code/notebooks/main/topic_model_analysis.ipynb">this notebook</a>; here we'll be downloading the resulting preprocessed text rather than reproducing it.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># preprocessed annotations</span>
<span class="n">preprocessed_source</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/ContextLab/sherlock-topic-model-paper/raw/revision-1/data/processed/video_text.npy&#39;</span>
<span class="n">preprocessed_dest</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">datadir</span><span class="p">,</span> <span class="s1">&#39;Sherlock&#39;</span><span class="p">,</span> <span class="s1">&#39;stimuli&#39;</span><span class="p">,</span> <span class="s1">&#39;video_text.npy&#39;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="n">preprocessed_source</span><span class="p">,</span> <span class="n">preprocessed_dest</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">preprocessed_dest</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's examine the text in a window somewhere near the middle:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text</span><span class="p">[</span><span class="mi">500</span><span class="p">][:</span><span class="mi">250</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;sherlock takes a deep breath through his nose outdoor sherlock donovan sherlock lauriston gardens  street  over the shoulder medium no sherlock i even know you didnt make it home last night outdoor sherlock donovan sherlock sherlock lauriston gardens...&#39;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we'll use HyperTools to train a topic model (<a href="http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf">Blei et al., 2003</a>) on the annotations, treating the text in each sliding window as a document.  We'll plot the result as a 3D shape.  (For an example of an alternative word embedding model, see the <a href="http://naturalistic-data.org/features/notebooks/Natural_Language_Processing.html">Natural Language Processing tutorial</a>.)</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_geometry</span> <span class="o">=</span> <span class="n">hyp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s1">&#39;UMAP&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Video content&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_31_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also visualize the timecourse of word embeddings for the movie as a heatmap.  Since we've already fit our topic model to the annotation text, HyperTools automatically uses the cached result (so the command runs quickly).  Here each row is a timepoint and each column is a topic dimension (i.e., a word embedding dimension):</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">topics</span> <span class="o">=</span> <span class="n">text_geometry</span><span class="o">.</span><span class="n">get_formatted_data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">topics</span><span class="p">)</span>
<span class="n">h</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Topics&#39;</span><span class="p">);</span>
<span class="n">h</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/hypertools_33_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Further-reading">Further reading<a class="anchor-link" href="#Further-reading"> </a></h1><p>For more in-depth explorations of the Sherlock data using HyperTools, check out <a href="https://www.biorxiv.org/content/10.1101/409987v1">this paper</a> along with the associated <a href="https://github.com/ContextLab/sherlock-topic-model-paper">code and data</a>.  For more in-depth HyperTools tutorials, take a look <a href="https://hypertools.readthedocs.io/en/latest/tutorials.html">here</a>.  <a href="https://github.com/ContextLab/hypertools-paper-notebooks">This repository</a> contains additional example applications of HyperTools to a variety of different data types.</p>

</div>
</div>
</div>
</div>

 


    </main>
    